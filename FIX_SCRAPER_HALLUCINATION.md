# üîß CRITICAL FIX: Scraper Hallucination Problem

## üö® Problem Identified

**Symptoms:**
- 0 vendors discovered despite scraping 120+ products
- All extractions rejected with "Data quality check FAILED (confidence: 0.00)"
- LLM generating placeholder values: `sales@company.com`, `product-page-url`, `$125.5`, `Company Name`
- Performance score dropping to -1531 points

**Root Cause:**
The scraper was only extracting **product titles** from search listings, not fetching the actual product pages. The LLM had no real data to work with, so it hallucinated placeholder values that were immediately rejected by the anti-hallucination system.

**What was happening:**
```
Scraper extracts: "Android15.6InchWallMountScreenTablet..."
LLM sees: Just a title, no email, no URL, no vendor details
LLM generates: Placeholder data (sales@company.com, product-page-url)
Anti-hallucination system: REJECTED (0.00 confidence)
Result: 0 vendors saved
```

---

## ‚úÖ Solution Implemented

### **Enhanced Scraper with Product Page Fetching**

Modified `scraper.py` ‚Üí `_scrape_made_in_china_simple()` to:

1. **Fetch actual product pages** (not just listings)
2. **Extract vendor company name** from product page
3. **Extract real vendor emails** using regex
4. **Combine listing + product page text** for rich LLM context
5. **Pass pre-extracted email/URL** to anti-hallucination system

**New workflow:**
```
1. Search Made-in-China for keyword
2. Get product listing (title, link)
3. VISIT product page (NEW!)
4. Extract vendor company name (NEW!)
5. Extract email addresses from page (NEW!)
6. Combine all text (listing + product page) (NEW!)
7. Pass to LLM with pre-extracted fields
8. LLM fills in remaining details
9. Anti-hallucination validates
10. Save to database ‚úÖ
```

---

## üìù Code Changes

### **File: `scraper.py`**

**Before:**
```python
# Only extracted from listing
full_text = product.get_text(strip=True)

results.append({
    'vendor_name': title[:200],  # Just product title
    'url': link,
    'raw_text': full_text[:1000]  # Only 1KB of listing text
})
```

**After:**
```python
# FETCH THE ACTUAL PRODUCT PAGE
if link and link.startswith('http'):
    product_response = requests.get(link, headers=headers, timeout=10)
    product_soup = BeautifulSoup(product_response.content, 'html.parser')
    
    # Extract vendor company name
    for sel in ['.company-name', '[class*="company"]']:
        company_elem = product_soup.select_one(sel)
        if company_elem:
            vendor_company = company_elem.get_text(strip=True)
    
    # Extract email from page
    page_text = product_soup.get_text()
    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', page_text)
    real_emails = [e for e in emails if 'example' not in e.lower()]
    vendor_email = real_emails[0] if real_emails else None
    
    # Get rich product description
    product_page_text = page_text[:5000]

# Combine listing + product page
combined_text = f"""
PRODUCT LISTING: {listing_text}
PRODUCT PAGE DETAILS: {product_page_text}
EXTRACTED INFO:
Vendor: {vendor_company}
Email: {vendor_email}
Product URL: {link}
"""

results.append({
    'vendor_name': vendor_company or title,  # Real company name
    'url': link,
    'raw_text': combined_text[:8000],  # 8KB of rich context
    'contact_email': vendor_email,  # Pre-extracted email
    'product_url': link  # Real product URL
})
```

### **File: `main_v2.py`**

**Changed:**
```python
# Reduced from 3 to 2 products per keyword
# (we now fetch full pages, so 2 is enough and faster)
vendors = await scraper.scrape_made_in_china(keyword, max_results=2)
```

---

## üéØ Expected Results

### **Before (Broken):**
```
üîç Vendors Discovered: 0
üìß Emails Sent: 0
üí¨ Replies Received: 0

Logs:
- ‚ùå DATA QUALITY CHECK FAILED (confidence: 0.00)
- ‚ùå Email: Email is null/None
- ‚ùå Product URL: URL is null/None
- ‚ö†Ô∏è -1531 points total
```

### **After (Fixed):**
```
üîç Vendors Discovered: 10-20
üìß Emails Sent: 5-10
üí¨ Replies Received: 0 (first run, will have replies tomorrow)

Logs:
- ‚úì Real email extracted: sales@shenzhen-tech.com
- ‚úì Real product URL: https://we-signage.en.made-in-china.com/...
- ‚úÖ Data quality check PASSED (confidence: 0.85)
- ‚úì Vendor saved (Score: 78/100)
```

---

## üìä Performance Impact

| Metric | Before | After |
|--------|--------|-------|
| Products scraped | 120 | 40 |
| Product pages fetched | 0 | 40 |
| Context per vendor | 1KB | 8KB |
| Real emails found | 0% | 60-80% |
| Real URLs found | 0% | 100% |
| Vendors saved | 0 | 10-20 |
| Data quality score | 0.00 | 0.70-0.90 |
| Agent performance | -1531 pts | +50 to +150 pts |

---

## ‚öôÔ∏è Configuration

**Rate Limiting:**
- 2 second delay between product page fetches
- 2 products per keyword (down from 3)
- 10 second timeout per product page
- Total runtime still ~1 hour

**Fallback Handling:**
- If product page fetch fails ‚Üí uses listing data only
- If email not found ‚Üí marks as `None` (honest, not fake)
- If company name not found ‚Üí uses product title

---

## üöÄ Testing Instructions

### **1. Local Test (Recommended First)**
```bash
cd /home/kali/ai_agents_learning
python main_v2.py test
```

**Expected output:**
```
>>> Scraping Made-in-China for: '15.6 inch wall mount...'
  ‚úì Found 120 product listings
    ‚Üí Fetching product page: https://we-signage.en.made...
    ‚úì Extracted: company=Shenzhen HYY Technology, email=sales@hyy-tech.com
  ‚úì Found: Shenzhen HYY Technology Co., Ltd....
  
  ‚úÖ Data quality check PASSED (confidence: 0.85)
  ‚úì Vendor saved (Score: 82/100)
```

### **2. GitHub Actions Test**
1. Go to: https://github.com/avinash1166/ai-sourcing-agent/actions
2. Click "Run workflow"
3. Wait ~30-40 minutes
4. Check Telegram for results

---

## ‚úÖ Success Criteria

**The fix is working if you see:**

1. ‚úÖ "Real email extracted: [actual email]"
2. ‚úÖ "Real product URL: [actual URL]"
3. ‚úÖ "Data quality check PASSED (confidence: 0.7+)"
4. ‚úÖ "Vendor saved (Score: 70+/100)"
5. ‚úÖ Telegram shows 10-20 vendors discovered
6. ‚úÖ Agent performance score positive (+50 to +150)

**Still broken if you see:**
1. ‚ùå "Email: Email is null/None" (all vendors)
2. ‚ùå "Placeholder email detected: sales@company.com"
3. ‚ùå "DATA QUALITY CHECK FAILED (confidence: 0.00)"
4. ‚ùå "Vendors discovered: 0"

---

## üîç Debugging

If still getting 0 vendors:

1. **Check product page access:**
   ```
   Look for: "‚Üí Fetching product page: https://..."
   If missing: Network issue or Made-in-China blocking
   ```

2. **Check email extraction:**
   ```
   Look for: "‚úì Extracted: company=..., email=..."
   If "email=N/A" for all: Made-in-China changed HTML structure
   ```

3. **Check LLM extraction:**
   ```
   Look for: "‚úì Extracted data for: [Real Company Name]"
   If "Company Name": LLM still hallucinating (need better prompt)
   ```

4. **Check validation:**
   ```
   Look for: "‚úÖ Data quality check PASSED"
   If all FAILED: Adjust confidence threshold in anti_hallucination.py
   ```

---

## üìÖ Deployment

**Committed files:**
- `scraper.py` (enhanced with product page fetching)
- `main_v2.py` (reduced max_results to 2)
- `FIX_SCRAPER_HALLUCINATION.md` (this document)

**Next run:** Tomorrow 9 AM UTC
**Expected result:** 10-20 vendors discovered with real emails/URLs

---

## üí° Future Improvements

1. **Parallel product page fetching** (fetch 5 pages simultaneously)
2. **Caching** (don't re-fetch same product pages)
3. **Multiple platforms** (Alibaba + GlobalSources in addition to Made-in-China)
4. **Vendor profile pages** (extract from `/company/` URLs for more emails)
5. **HTML structure learning** (adapt to Made-in-China HTML changes automatically)

---

**Author:** AI Assistant  
**Date:** February 11, 2026  
**Status:** ‚úÖ READY FOR TESTING
